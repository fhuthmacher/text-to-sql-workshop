{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Bedrock Text-to-SQL Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro and Goal\n",
    "This Jupyter Notebook is designed to illustrate Text-to-SQL evaluation.\n",
    "\n",
    "The goal is to take highlight programmatic evaluation metrics as well as LLM as a Judge.\n",
    "\n",
    "The notebook is structured as follows:\n",
    "1. Download ground truth dataset comprised of questions and SQL queries for a given database (e.g. Northwind)\n",
    "2. Evaluate accuracy, cost, and latency of different Text-to-SQL approaches compared to the baseline (zero-shot prompting) for all queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a python environment\n",
    "\n",
    "# !conda create -y --name bedrock-router-eval python=3.11.8\n",
    "# !conda init && activate bedrock-router-eval\n",
    "# !conda install -n bedrock-router-eval ipykernel --update-deps --force-reinstall -y\n",
    "# !conda install -c conda-forge ipython-sql\n",
    "\n",
    "## OR\n",
    "# !python -m venv venv\n",
    "# !source venv/bin/activate  # On Windows, use `venv\\Scripts\\activate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Install dependencies\n",
    "\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using database: SQLALCHEMY with sql dialect: PostgreSQL\n"
     ]
    }
   ],
   "source": [
    "# 3. Import necessary libraries and load environment variables\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import boto3\n",
    "import sqlite3\n",
    "from pandas.io import sql\n",
    "from botocore.config import Config\n",
    "import pandas as pd\n",
    "import io\n",
    "import json\n",
    "from io import StringIO\n",
    "import sqlparse\n",
    "import sqlite3\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import typing as t\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# loading environment variables that are stored in local file\n",
    "local_env_filename = 'dev.env'\n",
    "load_dotenv(find_dotenv(local_env_filename),override=True)\n",
    "\n",
    "os.environ['REGION'] = os.getenv('REGION')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')\n",
    "os.environ['SQL_DATABASE'] = os.getenv('SQL_DATABASE') # LOCAL, SQLALCHEMY, REDSHIFT\n",
    "os.environ['SQL_DIALECT'] = os.getenv('SQL_DIALECT') # SQlite, PostgreSQL\n",
    "\n",
    "\n",
    "REGION = os.environ['REGION']\n",
    "HF_TOKEN = os.environ['HF_TOKEN']\n",
    "SQL_DATABASE = os.environ['SQL_DATABASE']\n",
    "SQL_DIALECT = os.environ['SQL_DIALECT']\n",
    "\n",
    "MODEL_ID = \"anthropic.claude-3-haiku-20240307-v1:0\" #anthropic.claude-3-sonnet-20240229-v1:0\" # anthropic.claude-3-haiku-20240307-v1:0 \"anthropic.claude-3-5-sonnet-20240620-v1:0\" \"meta.llama3-1-70b-instruct-v1:0\"\n",
    "EVAL_MODEL_ID = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "# get ground truth data\n",
    "file_path = './data/ground_truth.jsonl'\n",
    "groundtruth_df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "print(f\"Using database: {SQL_DATABASE} with sql dialect: {SQL_DIALECT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Definition of helper classes\n",
    "\n",
    "class BedrockLLMWrapper():\n",
    "    def __init__(self,\n",
    "        model_id: str = 'anthropic.claude-3-sonnet-20240229-v1:0', # 'anthropic.claude-3-haiku-20240307-v1:0', #'anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "        top_k: int = 5,\n",
    "        top_p: int = 0.7,\n",
    "        temperature: float = 0.0,\n",
    "        max_token_count: int = 4000,\n",
    "        max_attempts: int = 3,\n",
    "        debug: bool = False\n",
    "\n",
    "    ):\n",
    "\n",
    "        self.model_id = model_id\n",
    "        self.top_k = top_k\n",
    "        self.top_p = top_p\n",
    "        self.temperature = temperature\n",
    "        self.max_token_count = max_token_count\n",
    "        self.max_attempts = max_attempts\n",
    "        self.debug = debug\n",
    "        config = Config(\n",
    "            retries = {\n",
    "                'max_attempts': 10,\n",
    "                'mode': 'standard'\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\", config=config, region_name=REGION)\n",
    "        \n",
    "    def generate(self,prompt):\n",
    "        if self.debug: \n",
    "            print('entered BedrockLLMWrapper generate')\n",
    "        attempt = 1\n",
    "\n",
    "        message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": prompt}]\n",
    "        }\n",
    "        messages = []\n",
    "        messages.append(message)\n",
    "        \n",
    "        # model specific inference parameters to use.\n",
    "        if \"anthropic\" in self.model_id.lower():\n",
    "            # system_prompts = [{\"text\": \"You are a helpful AI Assistant.\"}]\n",
    "            system_prompts = []\n",
    "            # Base inference parameters to use.\n",
    "            inference_config = {\n",
    "                                \"temperature\": self.temperature, \n",
    "                                \"maxTokens\": self.max_token_count,\n",
    "                                \"stopSequences\": [\"\\n\\nHuman:\"],\n",
    "                                \"topP\": self.top_p,\n",
    "                            }\n",
    "            additional_model_fields = {\"top_k\": self.top_k}\n",
    "        else:\n",
    "            system_prompts = []\n",
    "            # Base inference parameters to use.\n",
    "            inference_config = {\n",
    "                                \"temperature\": self.temperature, \n",
    "                                \"maxTokens\": self.max_token_count,\n",
    "                            }\n",
    "            additional_model_fields = {\"top_k\": self.top_k}\n",
    "\n",
    "        if self.debug: \n",
    "            print(\"Sending:\\nSystem:\\n\",system,\"\\nMessages:\\n\",str(messages))\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "\n",
    "                # Send the message.\n",
    "                response = self.bedrock_runtime.converse(\n",
    "                    modelId=self.model_id,\n",
    "                    messages=messages,\n",
    "                    system=system_prompts,\n",
    "                    inferenceConfig=inference_config,\n",
    "                    additionalModelRequestFields=additional_model_fields\n",
    "                )\n",
    "\n",
    "                # Log token usage.\n",
    "                text = response['output'].get('message').get('content')[0].get('text')\n",
    "                usage = response['usage']\n",
    "                latency = response['metrics'].get('latencyMs')\n",
    "\n",
    "                if self.debug: \n",
    "                    print(f'text: {text} ; and token usage: {usage} ; and query_time: {latency}')    \n",
    "                \n",
    "                break\n",
    "               \n",
    "            except Exception as e:\n",
    "                print(\"Error with calling Bedrock: \"+str(e))\n",
    "                attempt+=1\n",
    "                if attempt>self.max_attempts:\n",
    "                    print(\"Max attempts reached!\")\n",
    "                    result_text = str(e)\n",
    "                    break\n",
    "                else:#retry in 10 seconds\n",
    "                    print(\"retry\")\n",
    "                    time.sleep(10)\n",
    "\n",
    "        # return result_text\n",
    "        return [text,usage,latency]\n",
    "\n",
    "     # Threaded function for queue processing.\n",
    "    def thread_request(self, q, results):\n",
    "        while True:\n",
    "            try:\n",
    "                index, prompt = q.get(block=False)\n",
    "                data = self.generate(prompt)\n",
    "                results[index] = data\n",
    "            except Queue.Empty:\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f'Error with prompt: {str(e)}')\n",
    "                results[index] = str(e)\n",
    "            finally:\n",
    "                q.task_done()\n",
    "\n",
    "    def generate_threaded(self, prompts, max_workers=15):\n",
    "        results = [None] * len(prompts)\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_index = {executor.submit(self.generate, prompt): i for i, prompt in enumerate(prompts)}\n",
    "            for future in as_completed(future_to_index):\n",
    "                index = future_to_index[future]\n",
    "                try:\n",
    "                    results[index] = future.result()\n",
    "                except Exception as exc:\n",
    "                    print(f'Generated an exception: {exc}')\n",
    "                    results[index] = str(exc)\n",
    "        \n",
    "        return results\n",
    "\n",
    "class Util():\n",
    "    def __init__(self,\n",
    "        debug: bool = False\n",
    "\n",
    "    ):\n",
    "        self.debug = debug\n",
    "    \n",
    "    SCORE_PATTERN = r'<score>(.*?)</score>'\n",
    "    REASONING_PATTERN = r'<thinking>(.*?)</thinking>'\n",
    "    SQL_PATTERN = r'<[sS][qQ][lL]>(.*?)</[sS][qQ][lL]>'\n",
    "    DIFFICULTY_PATTERN = r'<difficulty>(.*?)</difficulty>'\n",
    "    USER_QUESTION_PATTERN = r'<user_question>(.*?)</user_question>'\n",
    "    SQL_DATABASE_SCHEMA_PATTERN = r'<sql_database_schema>(.*?)</sql_database_schema>'\n",
    "    SQL_DIALECT_PATTERN = r'<sql_dialect>(.*?)</sql_dialect>'\n",
    "\n",
    "\n",
    "    def compare_results(self, answer_results1, answer_results2):\n",
    "\n",
    "\n",
    "        # # Function to convert 'score' column\n",
    "        def convert_score(df):\n",
    "            # df['score'] = df['score'].map({'correct': 1, 'incorrect': 0})\n",
    "            df['score'] = pd.to_numeric(df['score'], errors='coerce').fillna(0).astype(int)\n",
    "            return df\n",
    "\n",
    "        # Apply the conversion to both dataframes\n",
    "        answer_results1 = convert_score(answer_results1)\n",
    "        answer_results2 = convert_score(answer_results2)\n",
    "\n",
    "        # Calculate the average values for each metric\n",
    "        metrics = ['score', 'latency' ,'cost', 'ex_score', 'em_score','ves_score']\n",
    "        \n",
    "        avg_results1 = [answer_results1[metric].mean() for metric in metrics]\n",
    "        avg_results2 = [answer_results2[metric].mean() for metric in metrics]\n",
    "\n",
    "        # Calculate percentage change, handling divide-by-zero and infinite cases\n",
    "        def safe_percent_change(a, b):\n",
    "            if pd.isna(a) or pd.isna(b):\n",
    "                return 0\n",
    "            if a == 0 and b == 0:\n",
    "                return 0\n",
    "            elif a == 0:\n",
    "                return 100  # Arbitrarily set to 100% increase if original value was 0\n",
    "            else:\n",
    "                change = (b - a) / a * 100\n",
    "                return change if np.isfinite(change) else 0\n",
    "\n",
    "        percent_change = [safe_percent_change(a, b) for a, b in zip(avg_results1, avg_results2)]\n",
    "\n",
    "        # Set up the bar chart\n",
    "        x = np.arange(len(metrics))\n",
    "        width = 0.5\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "        # Create the bars\n",
    "        bars = ax.bar(x, percent_change, width)\n",
    "\n",
    "        # Customize the chart\n",
    "        ax.set_ylabel('Percentage Change (%)')\n",
    "        ax.set_title('Percentage Change in Metrics (Results 2 vs Results 1)')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(metrics)\n",
    "\n",
    "        # Add a horizontal line at y=0\n",
    "        ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "        # Add value labels on top of each bar\n",
    "        def autolabel(rects):\n",
    "            for rect in rects:\n",
    "                height = rect.get_height()\n",
    "                ax.annotate(f'{height:.2f}%',\n",
    "                            xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                            xytext=(0, 3 if height >= 0 else -3),  # 3 points vertical offset\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha='center', va='bottom' if height >= 0 else 'top')\n",
    "\n",
    "        autolabel(bars)\n",
    "\n",
    "        # Color the bars based on positive (green) or negative (red) change\n",
    "        # For latency & cost, reverse the color logic\n",
    "        for bar, change, metric in zip(bars, percent_change, metrics):\n",
    "            if metric == 'latency' or metric == 'cost':\n",
    "                bar.set_color('green' if change <= 0 else 'red')\n",
    "            else:\n",
    "                bar.set_color('green' if change >= 0 else 'red')\n",
    "            \n",
    "\n",
    "        # Adjust layout and display the chart\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_distribution(self, df, key):\n",
    "        # Check if 'score' column exists in the DataFrame\n",
    "        if key not in df.columns:\n",
    "            raise ValueError(f\"The DataFrame does not contain a '{key}' column.\")\n",
    "        \n",
    "        # Count the frequency of each score\n",
    "        score_counts = df[key].value_counts().sort_index()\n",
    "        \n",
    "        # Create a bar chart\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(score_counts.index, score_counts.values)\n",
    "        \n",
    "        # Customize the chart\n",
    "        plt.title(f'Distribution of {key}')\n",
    "        plt.xlabel(f'{key}')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.xticks(range(int(score_counts.index.min()), int(score_counts.index.max()) + 1))\n",
    "        \n",
    "        # Add value labels on top of each bar\n",
    "        for i, v in enumerate(score_counts.values):\n",
    "            plt.text(score_counts.index[i], v, str(v), ha='center', va='bottom')\n",
    "        \n",
    "        # Display the chart\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Strip out the portion of the response with regex.\n",
    "    def extract_with_regex(self, response, regex):\n",
    "        matches = re.search(regex, response, re.DOTALL)\n",
    "        # Extract the matched content, if any\n",
    "        return matches.group(1).strip() if matches else None\n",
    "\n",
    "    def calculate_cost(self, usage, model_id):\n",
    "        '''\n",
    "        Takes the usage tokens returned by Bedrock in input and output, and coverts to cost in dollars.\n",
    "        '''\n",
    "        \n",
    "        input_token_haiku = 0.25/1000000\n",
    "        output_token_haiku = 1.25/1000000\n",
    "        input_token_sonnet = 3.00/1000000\n",
    "        output_token_sonnet = 15.00/1000000\n",
    "        input_token_opus = 15.00/1000000\n",
    "        output_token_opus = 75.00/1000000\n",
    "        \n",
    "        input_token_titan_embeddingv1 = 0.1/1000000\n",
    "        input_token_titan_embeddingv2 = 0.02/1000000\n",
    "        input_token_titan_embeddingmultimodal = 0.8/1000000\n",
    "        input_token_titan_premier = 0.5/1000000\n",
    "        output_token_titan_premier = 1.5/1000000\n",
    "        input_token_titan_lite = 0.15/1000000\n",
    "        output_token_titan_lite = 0.2/1000000\n",
    "        input_token_titan_express = 0.2/1000000\n",
    "        output_token_titan_express = 0.6/1000000\n",
    "       \n",
    "        input_token_cohere_command = 0.15/1000000\n",
    "        output_token_cohere_command = 2/1000000\n",
    "        input_token_cohere_commandlight = 0.3/1000000\n",
    "        output_token_cohere_commandlight = 0.6/1000000\n",
    "        input_token_cohere_commandrplus = 3/1000000\n",
    "        output_token_cohere_commandrplus = 15/1000000\n",
    "        input_token_cohere_commandr = 5/1000000\n",
    "        output_token_cohere_commandr = 1.5/1000000\n",
    "        input_token_cohere_embedenglish = 0.1/1000000\n",
    "        input_token_cohere_embedmultilang = 0.1/1000000\n",
    "\n",
    "        input_token_llama3_8b = 0.4/1000000\n",
    "        output_token_llama3_8b = 0.6/1000000\n",
    "        input_token_llama3_70b = 2.6/1000000\n",
    "        output_token_llama3_70b = 3.5/1000000\n",
    "\n",
    "        input_token_mistral_8b = 0.15/1000000\n",
    "        output_token_mistral_8b = 0.2/1000000\n",
    "        input_token_mistral_large = 4/1000000\n",
    "        output_token_mistral_large = 12/1000000\n",
    "\n",
    "        cost = 0\n",
    "\n",
    "        if 'haiku' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_haiku\n",
    "            cost+= usage['outputTokens']*output_token_haiku\n",
    "        if 'sonnet' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_sonnet\n",
    "            cost+= usage['outputTokens']*output_token_sonnet\n",
    "        if 'opus' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_opus\n",
    "            cost+= usage['outputTokens']*output_token_opus\n",
    "        if 'amazon.titan-embed-text-v1' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_titan_embeddingv1\n",
    "        if 'amazon.titan-embed-text-v2' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_titan_embeddingv2\n",
    "        if 'cohere.embed-multilingual' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_embedmultilang\n",
    "        if 'cohere.embed-english' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_embedenglish \n",
    "        if 'meta.llama3-8b-instruct' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_llama3_8b\n",
    "            cost+= usage['outputTokens']*output_token_llama3_8b\n",
    "        if 'meta.llama3-70b-instruct' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_llama3_70b\n",
    "            cost+= usage['outputTokens']*output_token_llama3_70b\n",
    "        if 'cohere.command-text' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_command\n",
    "            cost+= usage['outputTokens']*output_token_cohere_command\n",
    "        if 'cohere.command-light-text' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_commandlight\n",
    "            cost+= usage['outputTokens']*output_token_cohere_commandlight\n",
    "        if 'cohere.command-r-plus' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_commandrplus\n",
    "            cost+= usage['outputTokens']*output_token_cohere_commandrplus\n",
    "        if 'cohere.command-r' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_commandr\n",
    "            cost+= usage['outputTokens']*output_token_cohere_commandr\n",
    "        if 'amazon.titan-text-express' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_titan_express\n",
    "            cost+= usage['outputTokens']*output_token_titan_express\n",
    "        if 'amazon.titan-text-lite' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_titan_lite\n",
    "            cost+= usage['outputTokens']*output_token_titan_lite\n",
    "        if 'amazon.titan-text-premier' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_titan_premier\n",
    "            cost+= usage['outputTokens']*output_token_titan_premier\n",
    "        if 'mistral.mixtral-8x7b-instruct-v0:1' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_mistral_8b\n",
    "            cost+= usage['outputTokens']*output_token_mistral_8b\n",
    "\n",
    "        return cost\n",
    "\n",
    "\n",
    "# Utility class to get database schema, create tables, and run SQL queries\n",
    "import requests\n",
    "import sqlite3\n",
    "import re\n",
    "from pyathena import connect\n",
    "# import psycopg2\n",
    "from sqlalchemy import create_engine, MetaData, text\n",
    "\n",
    "\n",
    "class DatabaseUtil():\n",
    "    def __init__(self,\n",
    "        debug: bool = False,\n",
    "        datasource_url: [] = ['https://d3q8adh3y5sxpk.cloudfront.net/sql-workshop/data/redshift-sourcedb.sql'],\n",
    "        sql_database: str = 'LOCAL',\n",
    "        sql_database_name: str = 'dev',\n",
    "        region: str = 'us-east-1',\n",
    "        s3_bucketname: str = ''\n",
    "\n",
    "    ):\n",
    "        self.debug = debug\n",
    "        self.datasource_url = datasource_url\n",
    "        self.sql_database = sql_database\n",
    "        self.sql_database_name = sql_database_name\n",
    "        self.region = region\n",
    "        self.s3_bucketname = s3_bucketname\n",
    "\n",
    "    # retrieve AWS secret for database connection\n",
    "    def get_secret(self, secret_name):\n",
    "        session = boto3.session.Session()\n",
    "        client = session.client(service_name='secretsmanager', region_name=self.region)\n",
    "        get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "        return get_secret_value_response\n",
    "\n",
    "    def get_table_reflections(self, engine) -> MetaData:\n",
    "    \n",
    "        # Instantiate MetaData object\n",
    "        metadata = MetaData()\n",
    "        \n",
    "        # Reflect the database schema with the engine\n",
    "        metadata.reflect(bind=engine)\n",
    "        \n",
    "        return metadata\n",
    "\n",
    "    def convert_reflection_to_dict(self, metadata: MetaData) -> dict:\n",
    "        table_definitions: list[dict] = []\n",
    "        for table_name in metadata.tables:\n",
    "            definition = {}\n",
    "            definition['table'] = table_name\n",
    "            # The metadata.table[x].columns value is type sqlalchemy.sql.base.ReadOnlyColumnCollection\n",
    "            # Lets convert it into something more usable. c.type returns a SQLAlchemy object so we convert to string.\n",
    "            definition['columns'] = { c.name: str(c.type) for c in metadata.tables[table_name].columns }\n",
    "        \n",
    "            table_header = f\"Table: {table_name}\"\n",
    "            columns_definition = '\\n'.join([f\"Column: {c.name}, Type: {c.type}\" for c in metadata.tables[table_name].columns])\n",
    "            string_representation = f\"{table_header}\\n{columns_definition}\"\n",
    "        \n",
    "            definition['string_representation'] = string_representation\n",
    "        \n",
    "            table_definitions.append(definition)\n",
    "        \n",
    "        \n",
    "        # The metadata table is a FacadeDict object which is immutable so we need to remove unwanted tables in the new list.\n",
    "        table_names_to_exclude = set(['table_embedding', 'alembic_version'])\n",
    "        table_definitions = [d for d in table_definitions if d['table'] not in table_names_to_exclude]\n",
    "\n",
    "        return table_definitions\n",
    "    \n",
    "    def create_database_tables(self):\n",
    "        # Download the SQL files\n",
    "        \n",
    "            # create local db and import northwind database\n",
    "            for url in self.datasource_url:\n",
    "                response = requests.get(url)\n",
    "                sql_content = response.text\n",
    "                # Split the SQL content into individual statements\n",
    "                sql_statements = re.split(r';\\s*$', sql_content, flags=re.MULTILINE)\n",
    "                \n",
    "                if self.sql_database == 'LOCAL':\n",
    "                    try:\n",
    "                        # Create a SQLite database connection\n",
    "                        conn = sqlite3.connect('devdb.db')\n",
    "                        cursor = conn.cursor()\n",
    "\n",
    "                        # Execute each SQL statement\n",
    "                        for statement in sql_statements:\n",
    "                            # Skip empty statements\n",
    "                            if statement.strip():\n",
    "                                # print(f'statement: {statement}')\n",
    "                                # Replace PostgreSQL-specific syntax with SQLite equivalents\n",
    "                                statement = statement.replace('SERIAL PRIMARY KEY', 'INTEGER PRIMARY KEY AUTOINCREMENT')\n",
    "                                statement = statement.replace('::int', '')\n",
    "                                statement = statement.replace('::varchar', '')\n",
    "                                statement = statement.replace('::real', '')\n",
    "                                statement = statement.replace('::date', '')\n",
    "                                statement = statement.replace('::boolean', '')\n",
    "                                statement = statement.replace('public.', '')\n",
    "                                statement = re.sub(r'WITH \\(.*?\\)', '', statement)\n",
    "                                \n",
    "                                try:\n",
    "                                    cursor.execute(statement)\n",
    "                                except sqlite3.Error as e:\n",
    "                                    print(f\"Error executing statement: {e}\")\n",
    "\n",
    "                        # Commit the changes and close the connection\n",
    "                        conn.commit()\n",
    "                        conn.close()\n",
    "\n",
    "                        print(\"SQL execution completed.\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error creating tables: {e}\")\n",
    "                        raise\n",
    "\n",
    "                if self.sql_database == 'REDSHIFT':\n",
    "                    try:\n",
    "                        rdc = boto3.client('redshift-data')\n",
    "                        get_secret_value_response = self.get_secret(\"RedshiftCreds\")\n",
    "                        # parse REDSHIFT_CLUSTER_DETAILS to extract WorkgroupName, Database, DbUser\n",
    "                        WorkgroupName = json.loads(get_secret_value_response['SecretString']).get('workgroupname')\n",
    "                        Database = json.loads(get_secret_value_response['SecretString']).get('workgroupname')\n",
    "                        DbUser = json.loads(get_secret_value_response['SecretString']).get('username')\n",
    "\n",
    "                        for statement in sql_statements:\n",
    "                            try:        \n",
    "                                rdc.execute_statement(\n",
    "                                    WorkgroupName=WorkgroupName,\n",
    "                                    Database=Database,\n",
    "                                    DbUser=DbUser,\n",
    "                                    Sql=statement\n",
    "                                )\n",
    "                                \n",
    "                            except Exception as e:\n",
    "                                print(f\"Error executing statement: {e}\")\n",
    "                        print(\"SQL execution completed.\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error creating tables: {e}\")\n",
    "                        raise\n",
    "                \n",
    "                if self.sql_database =='SQLALCHEMY':\n",
    "                    # create tables in database\n",
    "                    try:\n",
    "                        # SQLALCHEMY_URL = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{SQL_DATABASE_NAME}\"\n",
    "                        get_secret_value_response = self.get_secret(\"SQLALCHEMY_URL\")\n",
    "                        SQLALCHEMY_URL = get_secret_value_response['SecretString']\n",
    "\n",
    "                        print(f\"SQLALCHEMY_URL: {SQLALCHEMY_URL}\")\n",
    "                        engine = create_engine(SQLALCHEMY_URL)\n",
    "                        with engine.connect() as connection:\n",
    "                            # Execute each SQL statement\n",
    "                            for statement in sql_statements:\n",
    "                                # Skip empty statements\n",
    "                                if statement.strip():\n",
    "                                    # print(f'statement: {statement}')\n",
    "                                    # Replace PostgreSQL-specific syntax with SQLite equivalents\n",
    "                                    statement = statement.replace('SERIAL PRIMARY KEY', 'INTEGER PRIMARY KEY AUTOINCREMENT')\n",
    "                                    statement = statement.replace('::int', '')\n",
    "                                    statement = statement.replace('::varchar', '')\n",
    "                                    statement = statement.replace('::real', '')\n",
    "                                    statement = statement.replace('::date', '')\n",
    "                                    statement = statement.replace('::boolean', '')\n",
    "                                    statement = statement.replace('public.', '')\n",
    "                                    statement = statement.replace('VARBYTE', 'bytea')\n",
    "                                    statement = statement.replace('bpchar', 'varchar')\n",
    "                                    \n",
    "                                    statement = re.sub(r'WITH \\(.*?\\)', '', statement)\n",
    "                                    \n",
    "                                    try:\n",
    "                                        connection.execute(text(statement))\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error executing statement: {e}\")\n",
    "                            connection.commit()\n",
    "                            print(\"SQL execution completed.\")    \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error creating tables: {e}\")\n",
    "                        raise\n",
    "\n",
    "\n",
    "    def get_schema_as_string(self):\n",
    "        if self.sql_database == 'LOCAL':\n",
    "            db_path = 'devdb.db'          \n",
    "            conn = sqlite3.connect(db_path)\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            # Query to get all table names\n",
    "            cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "            tables = cursor.fetchall()\n",
    "\n",
    "            schema_string = \"\"\n",
    "\n",
    "            for table in tables:\n",
    "                table_name = table[0]\n",
    "                # Query to get the CREATE TABLE statement for each table\n",
    "                cursor.execute(f\"SELECT sql FROM sqlite_master WHERE type='table' AND name='{table_name}';\")\n",
    "                create_table_stmt = cursor.fetchone()[0]\n",
    "                \n",
    "                schema_string += f\"{create_table_stmt};\\n\\n\"\n",
    "\n",
    "            conn.close()\n",
    "            return schema_string\n",
    "\n",
    "        if self.sql_database =='SQLALCHEMY':\n",
    "            try:\n",
    "                # Use SQLAlchemy if SQL Alchemy is used\n",
    "                # SQLALCHEMY_URL = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{SQL_DATABASE_NAME}\"\n",
    "                get_secret_value_response = self.get_secret(\"SQLALCHEMY_URL\")\n",
    "                SQLALCHEMY_URL = get_secret_value_response['SecretString']\n",
    "                \n",
    "                engine = create_engine(SQLALCHEMY_URL)\n",
    "                metadata = self.get_table_reflections(engine)\n",
    "                table_definitions = self.convert_reflection_to_dict(metadata)\n",
    "\n",
    "                return table_definitions\n",
    "                # with engine.connect() as connection:\n",
    "                #     result = connection.execute(\"\"\"\"\"\")\n",
    "                #     return result.fetchall()\n",
    "            except Exception as e:\n",
    "                error = f\"Error executing statement: {e}\"\n",
    "                print(error)\n",
    "\n",
    "        if self.sql_database == \"REDSHIFT\":\n",
    "            try:\n",
    "                get_secret_value_response = self.get_secret(\"RedshiftCreds\")\n",
    "                # parse REDSHIFT_CLUSTER_DETAILS to extract WorkgroupName, Database, DbUser\n",
    "                WorkgroupName = json.loads(get_secret_value_response['SecretString']).get('workgroupname')\n",
    "                Database = json.loads(get_secret_value_response['SecretString']).get('workgroupname')\n",
    "                DbUser = json.loads(get_secret_value_response['SecretString']).get('username')\n",
    "                \n",
    "                rdc = boto3.client('redshift-data')\n",
    "                result = rdc.execute_statement(\n",
    "                    WorkgroupName=WorkgroupName,\n",
    "                    Database=Database,\n",
    "                    DbUser=DbUser,\n",
    "                    Sql=f\"select * from pg_table_def where schemaname = 'public';\"\n",
    "                )\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                print(f\"Error executing statement: {e}\")\n",
    "      \n",
    "            \n",
    "        if self.sql_database == 'GLUE':\n",
    "            # use a Glue database\n",
    "            table_names=None\n",
    "            try:\n",
    "                glue_client = boto3.client('glue', region_name=self.region)\n",
    "                table_schema_list = []\n",
    "                response = glue_client.get_tables(DatabaseName=self.sql_database_name)\n",
    "\n",
    "                all_table_names = [table['Name'] for table in response['TableList']]\n",
    "\n",
    "                if table_names:\n",
    "                    table_names = [name for name in table_names if name in all_table_names]\n",
    "                else:\n",
    "                    table_names = all_table_names\n",
    "\n",
    "                for table_name in table_names:\n",
    "                    response = glue_client.get_table(DatabaseName=self.sql_database_name, Name=table_name)\n",
    "                    columns = response['Table']['StorageDescriptor']['Columns']\n",
    "                    schema = {column['Name']: column['Type'] for column in columns}\n",
    "                    table_schema_list.append({\"Table: {}\".format(table_name): 'Schema: {}'.format(schema)})\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {str(e)}\")\n",
    "            return table_schema_list\n",
    "        \n",
    "    def run_sql(self, statement):\n",
    "    \n",
    "        if self.sql_database == 'LOCAL':\n",
    "            try:\n",
    "                # Create a SQLite database connection\n",
    "                conn = sqlite3.connect('devdb.db')\n",
    "                cursor = conn.cursor()\n",
    "\n",
    "                cursor.execute(statement)\n",
    "                # Fetch all rows from the result\n",
    "                result = cursor.fetchall()\n",
    "                conn.close()\n",
    "                return result\n",
    "            except sqlite3.Error as e:\n",
    "                error = f\"Error executing statement: {e}\"\n",
    "                raise\n",
    "            \n",
    "            finally:\n",
    "                conn.close()\n",
    "                \n",
    "        if self.sql_database == 'GLUE':\n",
    "            try:\n",
    "                # Use Athena if AWS Glue Schema is used\n",
    "                athenacursor = connect(s3_staging_dir=f\"s3://{self.s3_bucketname}/athena/\",\n",
    "                                        region_name=self.region).cursor()\n",
    "                athenacursor.execute(statement)\n",
    "                result = pd.DataFrame(athenacursor.fetchall()).to_string(index=False)\n",
    "                # convert df to string\n",
    "                return result\n",
    "            \n",
    "            except Exception as e:\n",
    "                error = f\"Error executing statement: {e}\"\n",
    "                raise\n",
    "        \n",
    "        if self.sql_database == \"REDSHIFT\":\n",
    "            try:\n",
    "                get_secret_value_response = self.get_secret(\"RedshiftCreds\")\n",
    "                # parse REDSHIFT_CLUSTER_DETAILS to extract WorkgroupName, Database, DbUser\n",
    "                WorkgroupName = json.loads(get_secret_value_response['SecretString']).get('workgroupname')\n",
    "                Database = json.loads(get_secret_value_response['SecretString']).get('workgroupname')\n",
    "                DbUser = json.loads(get_secret_value_response['SecretString']).get('username')\n",
    "\n",
    "                rdc = boto3.client('redshift-data')\n",
    "                result = rdc.execute_statement(\n",
    "                    WorkgroupName=WorkgroupName,\n",
    "                    Database=Database,\n",
    "                    DbUser=DbUser,\n",
    "                    Sql=statement\n",
    "                )\n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                error = f\"Error executing statement: {e}\"\n",
    "                raise\n",
    "\n",
    "        if self.sql_database =='SQLALCHEMY':\n",
    "            try:\n",
    "                # SQLALCHEMY_URL = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{SQL_DATABASE_NAME}\"\n",
    "                get_secret_value_response = self.get_secret(\"SQLALCHEMY_URL\")\n",
    "                SQLALCHEMY_URL = get_secret_value_response['SecretString']\n",
    "                \n",
    "                engine = create_engine(SQLALCHEMY_URL)\n",
    "                with engine.connect() as connection:\n",
    "                    result = connection.execute(text(statement))\n",
    "                    return result.fetchall()\n",
    "            except Exception as e:\n",
    "                error = f\"Error executing statement: {e}\"\n",
    "                raise\n",
    "\n",
    "class AnswerTaskRunner:\n",
    "    def __init__(self, eval_df: pd.DataFrame, \n",
    "                 model_id:str = 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "                 eval_model_id:str = 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "                 sql_dialect=None,\n",
    "                 temperature: float = 0.0,\n",
    "                 max_token_count: int = 2000,\n",
    "                 max_attempts: int = 3, \n",
    "                 prompt_template: str = '',\n",
    "                 prompt_eval_template: str = '',\n",
    "                 datasource_url: str =[\"https://d3q8adh3y5sxpk.cloudfront.net/sql-workshop/data/redshift-sourcedb.sql\"],\n",
    "                 sql_database: str = \"LOCAL\"):\n",
    "        self.eval_df = eval_df\n",
    "        self.model_id = model_id\n",
    "        self.eval_model_id = eval_model_id\n",
    "        self.sql_dialect = sql_dialect\n",
    "        self.temperature = temperature\n",
    "        self.max_token_count = max_token_count\n",
    "        self.max_attempts = max_attempts\n",
    "        self.prompt_template = prompt_template\n",
    "        self.prompt_eval_template = prompt_eval_template\n",
    "        self.datasource_url = datasource_url\n",
    "        self.sql_database = sql_database\n",
    "        self.wrapper = BedrockLLMWrapper(model_id=self.model_id, \n",
    "                                         max_token_count=self.max_token_count,\n",
    "                                         temperature=self.temperature\n",
    "                                         )\n",
    "        self.eval_wrapper = BedrockLLMWrapper(model_id=self.eval_model_id, \n",
    "                                         max_token_count=self.max_token_count,\n",
    "                                         temperature=self.temperature\n",
    "                                         )\n",
    "        self.util = Util()\n",
    "        self.DatabaseUtil = DatabaseUtil(datasource_url=datasource_url,\n",
    "                                         sql_database= self.sql_database)\n",
    "\n",
    "\n",
    "    def get_prompt(self, user_question, sql_database_schema):\n",
    "        prompt = self.prompt_template.format(\n",
    "                    user_question=user_question,\n",
    "                    sql_database_schema=sql_database_schema,\n",
    "                    sql_dialect=self.sql_dialect\n",
    "                ) \n",
    "        return prompt\n",
    "\n",
    "\n",
    "    def build_grader_prompt(self, \n",
    "                            question: str, \n",
    "                            sql_schema: str, \n",
    "                            sql_query:str, \n",
    "                            sql_query_run_error, \n",
    "                            sql_query_run_result:str,\n",
    "                            groundtruth_sql_query:str,\n",
    "                            ex_score:str,\n",
    "                            em_score:str,\n",
    "                            ves_score:str):\n",
    "    \n",
    "        prompt = self.prompt_eval_template.format(\n",
    "                    question=question,\n",
    "                    sql_schema=sql_schema,\n",
    "                    sql_query= sql_query,\n",
    "                    sql_query_run_error= sql_query_run_error,\n",
    "                    sql_query_run_result= sql_query_run_result,\n",
    "                    groundtruth_sql_query= groundtruth_sql_query,\n",
    "                    ex_score=ex_score,\n",
    "                    em_score=em_score,\n",
    "                    ves_score=ves_score,\n",
    "                ) \n",
    "        return prompt\n",
    "\n",
    "\n",
    "    def execution_accuracy(self, generated_sql, labeled_sql):\n",
    "        \"\"\"\n",
    "        Calculate Execution Accuracy (EX)\n",
    "        \n",
    "        Args:\n",
    "        generated_sql (str): The SQL query generated by the model\n",
    "        labeled_sql (str): The labeled (ground truth) SQL query\n",
    "        \n",
    "        Returns:\n",
    "        float: 1.0 if the queries match, 0.0 otherwise\n",
    "        \"\"\"\n",
    "        # Normalize and compare the SQL queries\n",
    "        gen_normalized = sqlparse.format(generated_sql, strip_comments=True, reindent=True)\n",
    "        lab_normalized = sqlparse.format(labeled_sql, strip_comments=True, reindent=True)\n",
    "        return 1.0 if gen_normalized == lab_normalized else 0.0\n",
    "\n",
    "    def convert_to_str(self, result):\n",
    "        if isinstance(result, list):\n",
    "            return str(result)\n",
    "        return result\n",
    "\n",
    "    def exact_set_match_accuracy(self, generated_sql, labeled_sql):\n",
    "        \"\"\"\n",
    "        Calculate Exact Set Match Accuracy (EM)\n",
    "        \n",
    "        Args:\n",
    "        generated_sql (str): The SQL query generated by the model\n",
    "        labeled_sql (str): The labeled (ground truth) SQL query\n",
    "        db_connection: A database connection object\n",
    "        \n",
    "        Returns:\n",
    "        float: 1.0 if the result sets match, 0.0 otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Execute both queries\n",
    "            gen_result = self.DatabaseUtil.run_sql(generated_sql)\n",
    "            # print(f'labeled_sql: {gen_result} - result: {gen_result}')\n",
    "            lab_result = self.DatabaseUtil.run_sql(labeled_sql)\n",
    "            # print(f'labeled_sql: {labeled_sql} - result: {lab_result}')\n",
    "            gen_result = self.convert_to_str(gen_result)\n",
    "            lab_result = self.convert_to_str(lab_result)\n",
    "\n",
    "            # Compare the result sets\n",
    "            return 1.0 if gen_result==lab_result else 0.0\n",
    "        except Exception as e:\n",
    "            return 0.0\n",
    "\n",
    "\n",
    "    def valid_efficiency_score(self, generated_sql, labeled_sql):\n",
    "        \"\"\"\n",
    "        Calculate Valid Efficiency Score (VES)\n",
    "        \n",
    "        Args:\n",
    "        generated_sql (str): The SQL query generated by the model\n",
    "        labeled_sql (str): The labeled (ground truth) SQL query\n",
    "        db_connection: A database connection object\n",
    "        \n",
    "        Returns:\n",
    "        float: The VES score\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Execute both queries and measure execution time\n",
    "            gen_start = time.time()\n",
    "            gen_result = self.DatabaseUtil.run_sql(generated_sql)\n",
    "            gen_time = time.time() - gen_start\n",
    "            # print(f'generated_sql_execution_time: {gen_time}')\n",
    "            lab_start = time.time()\n",
    "            lab_result = self.DatabaseUtil.run_sql(labeled_sql)\n",
    "            lab_time = time.time() - lab_start\n",
    "            # print(f'labeled_sql_execution_time: {lab_time}')\n",
    "            \n",
    "            gen_result = self.convert_to_str(gen_result)\n",
    "            lab_result = self.convert_to_str(lab_result)\n",
    "\n",
    "            # Check if results match\n",
    "            if not gen_result==lab_result:\n",
    "                return 0.0\n",
    "            \n",
    "            # Calculate VES\n",
    "            ves = min(lab_time / gen_time, 1.0)\n",
    "            return ves\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing SQL: {e}\")\n",
    "            return 0.0\n",
    "\n",
    "\n",
    "    def run(self) -> pd.DataFrame:\n",
    "        # Make a copy of the dataframe so we don't modify the original.\n",
    "        df = pd.DataFrame(self.eval_df)\n",
    "        results = []\n",
    "        \n",
    "        # Prepare prompts for all questions\n",
    "        prompts = []\n",
    "        for _, row in df.iterrows():\n",
    "            question: str = row['Question']\n",
    "            sql_database_schema: str = row['Context']\n",
    "            model_prompt = self.get_prompt(question, sql_database_schema)\n",
    "            prompts.append(model_prompt)\n",
    "        \n",
    "        # Generate SQL queries using threaded approach\n",
    "        answers = self.wrapper.generate_threaded(prompts,max_workers=5)\n",
    "        \n",
    "        # bottleneck: from here on we are back to processing in sequence\n",
    "        for index, (answer, row) in enumerate(zip(answers, df.iterrows())):\n",
    "            _, row = row  # Unpack the row\n",
    "            question: str = row['Question']\n",
    "            sql_database_schema: str = row['Context']\n",
    "            groundtruth_sql_query: str = row['Query']\n",
    "            sql_query_run_error = None\n",
    "            sql_query_run_result = None\n",
    "            usage = 0\n",
    "            latency = 0\n",
    "            cost = 0\n",
    "            ex_score = 0\n",
    "            em_score = 0\n",
    "            ves_score = 0\n",
    "\n",
    "            if answer[1] is not None:\n",
    "                cost = self.util.calculate_cost(answer[1], self.model_id)\n",
    "                usage = json.dumps(answer[1])\n",
    "            \n",
    "            if answer[2] is not None:\n",
    "                latency = answer[2]\n",
    "            \n",
    "            if answer[0] is not None:\n",
    "                generated_sql_query = self.util.extract_with_regex(str(answer[0]), self.util.SQL_PATTERN).replace(\"\\\\\",\"\")\n",
    "            \n",
    "                # Calculate eval metrics\n",
    "                try:\n",
    "                    sql_query_run_result = self.DatabaseUtil.run_sql(generated_sql_query)\n",
    "                except Exception as e:\n",
    "                    sql_query_run_error = e\n",
    "                \n",
    "                # print(f'generated_sql: {generated_sql_query} - query_result: {sql_query_run_result}')\n",
    "                \n",
    "                ex_score = self.execution_accuracy(generated_sql_query, groundtruth_sql_query)\n",
    "                # print(f'ex_score: {ex_score}')\n",
    "                em_score = self.exact_set_match_accuracy(generated_sql_query, groundtruth_sql_query)\n",
    "                # print(f'em_score: {em_score}')\n",
    "                ves_score = self.valid_efficiency_score(generated_sql_query, groundtruth_sql_query)\n",
    "                # print(f'ves_score: {ves_score}')\n",
    "            \n",
    "            # Create eval prompt\n",
    "            prompt = self.build_grader_prompt(question=question, \n",
    "                                            sql_schema=sql_database_schema, \n",
    "                                            sql_query=generated_sql_query, \n",
    "                                            sql_query_run_error=sql_query_run_error,\n",
    "                                            sql_query_run_result=sql_query_run_result,\n",
    "                                            groundtruth_sql_query=groundtruth_sql_query,\n",
    "                                            ex_score=ex_score,\n",
    "                                            em_score=em_score,\n",
    "                                            ves_score=ves_score)\n",
    "            \n",
    "            # Parse eval results\n",
    "            eval_result = self.eval_wrapper.generate(prompt)\n",
    "            reasoning = self.util.extract_with_regex(str(eval_result[0]), self.util.REASONING_PATTERN)\n",
    "            score = self.util.extract_with_regex(str(eval_result[0]), self.util.SCORE_PATTERN)\n",
    "            \n",
    "            # Create new record\n",
    "            result = {\n",
    "                'user_question': question,\n",
    "                'groundtruth_query': groundtruth_sql_query,\n",
    "                'generated_sql_query': generated_sql_query,\n",
    "                'score': score,\n",
    "                'reasoning': reasoning,\n",
    "                'usage': usage,\n",
    "                'latency': latency,\n",
    "                'cost': cost,\n",
    "                'ex_score': ex_score,\n",
    "                'em_score': em_score,\n",
    "                'ves_score': ves_score,\n",
    "                'sql_query_run_error': sql_query_run_error,\n",
    "                'sql_query_run_result': sql_query_run_result,\n",
    "                'context': sql_database_schema,\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        new_dataframe = pd.DataFrame(results)\n",
    "        return new_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Grading prompt\n",
    "\n",
    "evaluation_template = \"\"\"You are a SQL expert. \n",
    "                Your task is to evaluate a given SQL query based on a provided SQL schema and question using the criteria provided below.\n",
    " \n",
    "                Evaluation Criteria (Additive Score, 0-5):\n",
    "                1. Context: Award 1 point if the generated SQL query uses only information provided in the SQL schema, without introducing external or fabricated details.\n",
    "                2. Completeness: Add 1 point if the generated SQL query addresses all key elements of the question based on the available SQL schema and Exact Set Match Accuracy (EM) score.\n",
    "                3. ExecutionAccuracy: Add 1 point if the generated SQL query is very close to the groundtruth answer based on Execution Accuracy score.\n",
    "                4. Faultless: Add 1 point if the generated SQL query ran without any errors.\n",
    "                5. ValidEfficiencyScore:  Add 1 point if the runtime of the generated SQL query is similar or better than the the groundtruth qery as measured by the Valid Efficiency Score (VES).\n",
    "                \n",
    "                Evaluation Steps:\n",
    "                1. Read provided context, question and answer carefully.\n",
    "                2. Go through each evaluation criterion one by one and assess whether the answer meets the criteria.\n",
    "                3. Compose your reasoning for each critera, explaining why you did or did not award a point. You can only award full points. \n",
    "                4. Calculate the total score by summing the points awarded.\n",
    "                5. Think through the evaluation criteria inside <thinking></thinking> tags. \n",
    "                Then, output the total score inside <score></score> tags.\n",
    "                Review your formatted response. It needs to be valid XML.\n",
    "    \n",
    "                Original question:\n",
    "                <question>\n",
    "                {question}\n",
    "                </question>\n",
    "\n",
    "                SQL schema:\n",
    "                <sql_schema>\n",
    "                {sql_schema}\n",
    "                </sql_schema>\n",
    "\n",
    "                Generated SQL query based on these instructions:\n",
    "                <sql_query>\n",
    "                {sql_query}\n",
    "                </sql_query>\n",
    "\n",
    "                SQL result based on the generated SQL query:\n",
    "                <sql_query_run_result>\n",
    "                {sql_query_run_result}\n",
    "                </sql_query_run_result>\n",
    "\n",
    "                Any SQL errors that might have occured based on the generated SQL query:\n",
    "                <sql_query_run_error>\n",
    "                {sql_query_run_error}\n",
    "                </sql_query_run_error>\n",
    "\n",
    "                Groundtruth SQL query for comparison with the generated SQL query:\n",
    "                <groundtruth_sql_query>\n",
    "                {groundtruth_sql_query}\n",
    "                </groundtruth_sql_query>\n",
    "                \n",
    "                Execution Accuracy, which compares the generated SQL query to the labeled SQL query to determine if its a match or not: \n",
    "                <ex_score>\n",
    "                {ex_score}\n",
    "                </ex_score>\n",
    "                \n",
    "                Exact Set Match Accuracy (EM), which evaluates if the returned result set actually answer the question, regardless of how the query was written: \n",
    "                <em_score>\n",
    "                {em_score}\n",
    "                </em_score>\n",
    "\n",
    "                Valid Efficiency Score (VES), which compares the runtime of the SQL provided as groundtruth to the generated SQL query:\n",
    "                <ves_score>\n",
    "                {ves_score}\n",
    "                </ves_score>                \n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Run eval with zero-shot template \n",
    "# Zero-shot SQL prompt template to establish baseline\n",
    "\n",
    "## added \"Always prefix table names with the \"public.\" prefix.\" to support running queries via sqlalchemy \n",
    "zero_shot_sql_template = \"\"\"You are a SQL expert. You will be provided with the original user question and a SQL database schema. \n",
    "                Only return the SQL query and nothing else.\n",
    "                \n",
    "                User question:\n",
    "                <user_question>\n",
    "                {user_question}\n",
    "                </user_question>\n",
    "\n",
    "                SQL database schema:\n",
    "                <sql_database_schema>\n",
    "                {sql_database_schema}\n",
    "                </sql_database_schema>\n",
    "                \n",
    "                SQL dialect:\n",
    "                <sql_dialect>\n",
    "                {sql_dialect}\n",
    "                </sql_dialect>\n",
    "\n",
    "                Instructions:\n",
    "                Generate a SQL query that answers the original user question.\n",
    "                Use the schema, first create a syntactically correct {sql_dialect} query to answer the question. \n",
    "                Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
    "                Always prefix table names with the \"public.\" prefix.\n",
    "                Pay attention to use only the column names that you can see in the schema description. \n",
    "                Be careful to not query for columns that do not exist. \n",
    "                Pay attention to which column is in which table. \n",
    "                Also, qualify column names with the table name when needed.\n",
    "                If you cannot answer the user question with the help of the provided SQL database schema, \n",
    "                then output that this question question cannot be answered based of the information stored in the database.\n",
    "                You are required to use the following format, each taking one line:\n",
    "                Return the sql query inside the <sql></sql> tab.\n",
    "                \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "answer_results1: pd.DataFrame = AnswerTaskRunner(groundtruth_df[:10],\n",
    "                 model_id=MODEL_ID,\n",
    "                 eval_model_id=EVAL_MODEL_ID,\n",
    "                 sql_database=SQL_DATABASE,\n",
    "                 sql_dialect=SQL_DIALECT,\n",
    "                 prompt_template=zero_shot_sql_template,\n",
    "                 prompt_eval_template=evaluation_template).run()\n",
    "\n",
    "answer_results1.to_json('./data/zero-shot-graded.jsonl', orient='records', lines=True, force_ascii=False, date_format='iso', default_handler=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_question</th>\n",
       "      <th>groundtruth_query</th>\n",
       "      <th>generated_sql_query</th>\n",
       "      <th>score</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>usage</th>\n",
       "      <th>latency</th>\n",
       "      <th>cost</th>\n",
       "      <th>ex_score</th>\n",
       "      <th>em_score</th>\n",
       "      <th>ves_score</th>\n",
       "      <th>sql_query_run_error</th>\n",
       "      <th>sql_query_run_result</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the total number of customers?</td>\n",
       "      <td>SELECT COUNT(*) FROM customers;</td>\n",
       "      <td>SELECT COUNT(*) AS total_customers\\nFROM custo...</td>\n",
       "      <td>4</td>\n",
       "      <td>Context (1 point):\\nThe generated SQL query us...</td>\n",
       "      <td>{\"inputTokens\": 1532, \"outputTokens\": 23, \"tot...</td>\n",
       "      <td>637</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942588</td>\n",
       "      <td>None</td>\n",
       "      <td>[(91)]</td>\n",
       "      <td>CREATE TABLE categories (\\n    category_id sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>List all product names and their unit prices.</td>\n",
       "      <td>SELECT product_name, unit_price FROM products;</td>\n",
       "      <td>SELECT p.product_name, p.unit_price\\nFROM prod...</td>\n",
       "      <td>5</td>\n",
       "      <td>Context: The generated SQL query uses only the...</td>\n",
       "      <td>{\"inputTokens\": 1533, \"outputTokens\": 28, \"tot...</td>\n",
       "      <td>468</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>[(Chai, 18.0), (Chang, 19.0), (Aniseed Syrup, ...</td>\n",
       "      <td>CREATE TABLE categories (\\n    category_id sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who are the top 5 customers by order count?</td>\n",
       "      <td>SELECT c.company_name, COUNT(o.order_id) as or...</td>\n",
       "      <td>SELECT customers.customer_id, customers.compan...</td>\n",
       "      <td>3</td>\n",
       "      <td>1. Context: The generated SQL query uses only ...</td>\n",
       "      <td>{\"inputTokens\": 1536, \"outputTokens\": 81, \"tot...</td>\n",
       "      <td>1098</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>[(SAVEA, Save-a-lot Markets, 31), (ERNSH, Erns...</td>\n",
       "      <td>CREATE TABLE categories (\\n    category_id sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the average freight cost for orders?</td>\n",
       "      <td>SELECT AVG(freight) FROM orders;</td>\n",
       "      <td>SELECT AVG(o.freight) AS average_freight_cost\\...</td>\n",
       "      <td>5</td>\n",
       "      <td>Context: The generated SQL query uses only the...</td>\n",
       "      <td>{\"inputTokens\": 1533, \"outputTokens\": 30, \"tot...</td>\n",
       "      <td>712</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.702572</td>\n",
       "      <td>None</td>\n",
       "      <td>[(78.244204877492)]</td>\n",
       "      <td>CREATE TABLE categories (\\n    category_id sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>List all employees with their full names and t...</td>\n",
       "      <td>SELECT employee_id, first_name || ' ' || last_...</td>\n",
       "      <td>SELECT e.first_name, e.last_name, e.title\\nFRO...</td>\n",
       "      <td>2</td>\n",
       "      <td>Context:\\nThe generated SQL query uses only th...</td>\n",
       "      <td>{\"inputTokens\": 1534, \"outputTokens\": 32, \"tot...</td>\n",
       "      <td>553</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>[(Andrew, Fuller, Vice President, Sales), (Jan...</td>\n",
       "      <td>CREATE TABLE categories (\\n    category_id sma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       user_question  \\\n",
       "0             What is the total number of customers?   \n",
       "1      List all product names and their unit prices.   \n",
       "2        Who are the top 5 customers by order count?   \n",
       "3       What is the average freight cost for orders?   \n",
       "4  List all employees with their full names and t...   \n",
       "\n",
       "                                   groundtruth_query  \\\n",
       "0                    SELECT COUNT(*) FROM customers;   \n",
       "1     SELECT product_name, unit_price FROM products;   \n",
       "2  SELECT c.company_name, COUNT(o.order_id) as or...   \n",
       "3                   SELECT AVG(freight) FROM orders;   \n",
       "4  SELECT employee_id, first_name || ' ' || last_...   \n",
       "\n",
       "                                 generated_sql_query score  \\\n",
       "0  SELECT COUNT(*) AS total_customers\\nFROM custo...     4   \n",
       "1  SELECT p.product_name, p.unit_price\\nFROM prod...     5   \n",
       "2  SELECT customers.customer_id, customers.compan...     3   \n",
       "3  SELECT AVG(o.freight) AS average_freight_cost\\...     5   \n",
       "4  SELECT e.first_name, e.last_name, e.title\\nFRO...     2   \n",
       "\n",
       "                                           reasoning  \\\n",
       "0  Context (1 point):\\nThe generated SQL query us...   \n",
       "1  Context: The generated SQL query uses only the...   \n",
       "2  1. Context: The generated SQL query uses only ...   \n",
       "3  Context: The generated SQL query uses only the...   \n",
       "4  Context:\\nThe generated SQL query uses only th...   \n",
       "\n",
       "                                               usage  latency      cost  \\\n",
       "0  {\"inputTokens\": 1532, \"outputTokens\": 23, \"tot...      637  0.000412   \n",
       "1  {\"inputTokens\": 1533, \"outputTokens\": 28, \"tot...      468  0.000418   \n",
       "2  {\"inputTokens\": 1536, \"outputTokens\": 81, \"tot...     1098  0.000485   \n",
       "3  {\"inputTokens\": 1533, \"outputTokens\": 30, \"tot...      712  0.000421   \n",
       "4  {\"inputTokens\": 1534, \"outputTokens\": 32, \"tot...      553  0.000423   \n",
       "\n",
       "   ex_score  em_score  ves_score sql_query_run_error  \\\n",
       "0       0.0       1.0   0.942588                None   \n",
       "1       0.0       1.0   1.000000                None   \n",
       "2       0.0       0.0   0.000000                None   \n",
       "3       0.0       1.0   0.702572                None   \n",
       "4       0.0       0.0   0.000000                None   \n",
       "\n",
       "                                sql_query_run_result  \\\n",
       "0                                             [(91)]   \n",
       "1  [(Chai, 18.0), (Chang, 19.0), (Aniseed Syrup, ...   \n",
       "2  [(SAVEA, Save-a-lot Markets, 31), (ERNSH, Erns...   \n",
       "3                                [(78.244204877492)]   \n",
       "4  [(Andrew, Fuller, Vice President, Sales), (Jan...   \n",
       "\n",
       "                                             context  \n",
       "0  CREATE TABLE categories (\\n    category_id sma...  \n",
       "1  CREATE TABLE categories (\\n    category_id sma...  \n",
       "2  CREATE TABLE categories (\\n    category_id sma...  \n",
       "3  CREATE TABLE categories (\\n    category_id sma...  \n",
       "4  CREATE TABLE categories (\\n    category_id sma...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_results1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Run eval with few-shot template  ( TO DO )\n",
    "# Few-shot SQL prompt template to establish baseline\n",
    "few_shot_sql_template = \"\"\"You are a SQL expert. You will be provided with the original user question and a SQL database schema. \n",
    "                Only return the SQL query and nothing else.\n",
    "                \n",
    "                User question:\n",
    "                <user_question>\n",
    "                {user_question}\n",
    "                </user_question>\n",
    "\n",
    "                SQL database schema:\n",
    "                <sql_database_schema>\n",
    "                {sql_database_schema}\n",
    "                </sql_database_schema>\n",
    "                \n",
    "                SQL dialect:\n",
    "                <sql_dialect>\n",
    "                {sql_dialect}\n",
    "                </sql_dialect>\n",
    "\n",
    "                Instructions:\n",
    "                Generate a SQL query that answers the original user question.\n",
    "                Use the schema, first create a syntactically correct {sql_dialect} query to answer the question. \n",
    "                Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
    "                Pay attention to use only the column names that you can see in the schema description. \n",
    "                Be careful to not query for columns that do not exist. \n",
    "                Pay attention to which column is in which table. \n",
    "                Also, qualify column names with the table name when needed.\n",
    "                If you cannot answer the user question with the help of the provided SQL database schema, \n",
    "                then output that this question question cannot be answered based of the information stored in the database.\n",
    "                You are required to use the following format, each taking one line:\n",
    "                Return the sql query inside the <sql></sql> tab.\n",
    "                \"\"\"\n",
    "\n",
    "answer_results2: pd.DataFrame = AnswerTaskRunner(groundtruth_df,\n",
    "                 model_id=MODEL_ID,\n",
    "                 eval_model_id=EVAL_MODEL_ID,\n",
    "                 sql_database=SQL_DATABASE,\n",
    "                 sql_dialect=SQL_DIALECT,\n",
    "                 prompt_template=few_shot_sql_template,\n",
    "                 prompt_eval_template=evaluation_template).run()\n",
    "\n",
    "answer_results2.to_json('./data/few-shot-graded.jsonl', orient='records', lines=True, force_ascii=False, date_format='iso', default_handler=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8. Compare results\n",
    "util = Util()\n",
    "# util.compare_results(answer_results2, answer_results1)\n",
    "util.visualize_distribution(answer_results1,key='score')\n",
    "# util.visualize_distribution(answer_results2,key='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of zero_shot_cost: 0.0044065\n",
      "avg of zero_shot_query_time: 1046.0\n",
      "avg of ex_score of zero_shot: 0.0\n",
      "avg of em_score of zero_shot: 0.6\n",
      "avg of ves_score of zero_shot: 0.5567783791694143\n"
     ]
    }
   ],
   "source": [
    "# 9. Review results\n",
    "print(f'sum of zero_shot_cost: {answer_results1[\"cost\"].sum()}')\n",
    "# print(f'sum of few_shot_cost: {answer_results2[\"cost\"].sum()}')\n",
    "\n",
    "print(f'avg of zero_shot_query_time: {answer_results1[\"latency\"].mean()}')\n",
    "# print(f'avg of few_shot_query_time: {answer_results2[\"latency\"].mean()}')\n",
    "\n",
    "# Execution Accuracy, which compares the generated router SQL query to the SQL query generated by the larger LLM to determine if its a match\n",
    "print(f'avg of ex_score of zero_shot: {answer_results1[\"ex_score\"].mean()}')\n",
    "# Exact Set Match Accuracy (EM), which evaluates if the generated router SQL query resultset matches the SQL query generated resultset by the larger LLM\n",
    "print(f'avg of em_score of zero_shot: {answer_results1[\"em_score\"].mean()}')\n",
    "# Valid Efficiency Score (VES), which compares the  generated router SQL query runtime provided to the generated SQL query from the larger LLM\n",
    "print(f'avg of ves_score of zero_shot: {answer_results1[\"ves_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Run eval with finetuned LLM ( TO DO )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Compare results\n",
    "util = Util()\n",
    "util.compare_results(answer_results3, answer_results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Review results (TO BE UPDATED)\n",
    "print(f'sum of zero_cost: {answer_results1[\"cost\"].sum()}')\n",
    "print(f'sum of large_cost: {answer_results2[\"cost\"].sum()}')\n",
    "\n",
    "print(f'avg of small_query_time: {answer_results1[\"latency\"].mean()}')\n",
    "print(f'avg of large_query_time: {answer_results2[\"latency\"].mean()}')\n",
    "\n",
    "# Execution Accuracy, which compares the generated router SQL query to the SQL query generated by the larger LLM to determine if its a match\n",
    "print(f'avg of ex_score of answer_results1: {answer_results1[\"ex_score\"].mean()}')\n",
    "# Exact Set Match Accuracy (EM), which evaluates if the generated router SQL query resultset matches the SQL query generated resultset by the larger LLM\n",
    "print(f'avg of em_scoreof answer_results: {answer_results1[\"em_score\"].mean()}')\n",
    "# Valid Efficiency Score (VES), which compares the  generated router SQL query runtime provided to the generated SQL query from the larger LLM\n",
    "print(f'avg of ves_score of answer_results1: {answer_results1[\"ves_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "XXX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock-router-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
