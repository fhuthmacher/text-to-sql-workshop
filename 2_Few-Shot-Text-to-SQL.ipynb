{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Bedrock Text-to-SQL - Few Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro and Goal\n",
    "This Jupyter Notebook is designed to illustrate a few-shot Text-to-SQL approach on the Northwind database.\n",
    "\n",
    "The goal is to take a user prompt along with a SQL database schema, supplement the prompt the prompt with relevant samples, and then generate a corresponding SQL query.\n",
    "\n",
    "### Steps\n",
    "1. Download SQL schema\n",
    "2. Download ground truth dataset comprised of questions and SQL queries for a given database (e.g. Northwind)\n",
    "3. Generate and run SQL queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import necessary libraries and load environment variables\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "# loading environment variables that are stored in local file\n",
    "local_env_filename = 'dev.env'\n",
    "load_dotenv(find_dotenv(local_env_filename),override=True)\n",
    "\n",
    "os.environ['REGION'] = os.getenv('REGION')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')\n",
    "os.environ['SQL_DATABASE'] = os.getenv('SQL_DATABASE') # LOCAL, SQLALCHEMY, REDSHIFT\n",
    "os.environ['SQL_DIALECT'] = os.getenv('SQL_DIALECT') # SQlite, PostgreSQL\n",
    "\n",
    "\n",
    "REGION = os.environ['REGION']\n",
    "HF_TOKEN = os.environ['HF_TOKEN']\n",
    "SQL_DATABASE = os.environ['SQL_DATABASE']\n",
    "SQL_DIALECT = os.environ['SQL_DIALECT']\n",
    "\n",
    "print(f\"Using database: {SQL_DATABASE} with sql dialect: {SQL_DIALECT}\")\n",
    "\n",
    "# File path to ground truth dataset\n",
    "file_path = \"./data/ground_truth.jsonl\"\n",
    "ground_truth_df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "file_path = \"./data/synthetic_data.jsonl\"\n",
    "few_shot_examples_df = pd.read_json(file_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize Chroma client from our persisted store\n",
    "import chromadb\n",
    "import boto3\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Initialize Chroma client from our persisted store\n",
    "chroma_client = chromadb.PersistentClient(path=\"../data/chroma\")\n",
    "\n",
    "# Also initialize the bedrock client so we can call some embedding models!\n",
    "session = boto3.Session()\n",
    "bedrock = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. create chunks for the few-shot examples\n",
    "\n",
    "from utils.splitter import DataFrameChunkingStrategy, RAGChunk\n",
    "\n",
    "# TO BE UPDATED WITH ACTUAL SAMPLES\n",
    "relevant_df = few_shot_examples_df[['Question', 'Query']]\n",
    "\n",
    "chunking_strategy = DataFrameChunkingStrategy(relevant_df)\n",
    "\n",
    "# Get the nodes from the chunker.\n",
    "chunks: RAGChunk = chunking_strategy.process()\n",
    "\n",
    "\n",
    "# print # of chunks\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "\n",
    "# print first 3 chunks\n",
    "print(f\"First 3 chunks: {chunks[:3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create embeddings for the few-shot examples\n",
    "\n",
    "from chromadb.utils.embedding_functions import AmazonBedrockEmbeddingFunction\n",
    "from utils.chroma import BaseRetrievalTask, ChromaDBRetrievalTask\n",
    "# Define some experiment variables\n",
    "TITAN_TEXT_EMBED_V2_ID: str = 'amazon.titan-embed-text-v2:0'\n",
    "COLLECTION_NAME: str = 'sqlsamples_collection'\n",
    "\n",
    "embedding_function = AmazonBedrockEmbeddingFunction(\n",
    "    session=session,\n",
    "    model_name=TITAN_TEXT_EMBED_V2_ID\n",
    ")\n",
    "\n",
    "retrieval_task: BaseRetrievalTask = ChromaDBRetrievalTask(\n",
    "    chroma_client = chroma_client, \n",
    "    collection_name = COLLECTION_NAME,\n",
    "    embedding_function = embedding_function,\n",
    "    chunks = chunks\n",
    ")\n",
    "\n",
    "# If you've already created collection, comment out this line\n",
    "retrieval_task.add_chunks_to_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Text-to-SQL dynamic few-shot prompt\n",
    "def build_sqlquerygen_prompt(user_question: str, sql_database_schema: str):\n",
    "    sql_examples = retrieval_task.retrieve(query_text=user_question, n_results=3)\n",
    "    \n",
    "    sql_examples_str = \"\\n\".join([example.document for example in sql_examples])\n",
    "\n",
    "    prompt = \"\"\"You are a SQL expert. You will be provided with the original user question and a SQL database schema. \n",
    "                Only return the SQL query and nothing else.\n",
    "                Here is the original user question.\n",
    "                <user_question>\n",
    "                {user_question}\n",
    "                </user_question>\n",
    "\n",
    "                Here is the SQL database schema.\n",
    "                <sql_database_schema>\n",
    "                {sql_database_schema}\n",
    "                </sql_database_schema>\n",
    "\n",
    "                Here are some examples of SQL queries that answer similar questions:\n",
    "                <sql_examples>\n",
    "                {sql_examples}\n",
    "                </sql_examples>\n",
    "                \n",
    "                Instructions:\n",
    "                Generate a SQL query that answers the original user question.\n",
    "                Use the schema, first create a syntactically correct {sql_dialect} query to answer the question. \n",
    "                Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
    "                Always prefix table names with the \"public.\" prefix.\n",
    "                Pay attention to use only the column names that you can see in the schema description. \n",
    "                Be careful to not query for columns that do not exist. \n",
    "                Pay attention to which column is in which table. \n",
    "                Also, qualify column names with the table name when needed.\n",
    "                If you cannot answer the user question with the help of the provided SQL database schema, \n",
    "                then output that this question question cannot be answered based of the information stored in the database.\n",
    "                You are required to use the following format, each taking one line.\n",
    "                Return the sql query inside the <SQL></SQL> tab.\n",
    "                \"\"\".format(\n",
    "                    user_question=user_question,\n",
    "                    sql_database_schema=sql_database_schema,\n",
    "                    sql_dialect=SQL_DIALECT,\n",
    "                    sql_examples=sql_examples_str\n",
    "                ) \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8b. Use ground truth to run test with larger LLM\n",
    "from utils.bedrock import BedrockLLMWrapper\n",
    "from utils.database import DatabaseUtil\n",
    "from utils.util import Util\n",
    "MODEL_ID = \"anthropic.claude-3-haiku-20240307-v1:0\" #\"anthropic.claude-3-sonnet-20240229-v1:0\"  \"mistral.mixtral-8x7b-instruct-v0:1\" \"anthropic.claude-3-5-sonnet-20240620-v1:0\" \"meta.llama3-1-70b-instruct-v1:0\"\n",
    "\n",
    "# use helper class for threaded API calls\n",
    "llm = BedrockLLMWrapper(model_id=MODEL_ID, max_token_count=500, region=REGION)\n",
    "util = Util()\n",
    "databaseutil = DatabaseUtil(\n",
    "                        datasource_url=[\"https://d3q8adh3y5sxpk.cloudfront.net/sql-workshop/data/redshift-sourcedb.sql\"],\n",
    "                        sql_database= 'SQLALCHEMY',\n",
    "                        region=REGION\n",
    "        )\n",
    "\n",
    "df2 = ground_truth_df\n",
    "prompts_list = []\n",
    "for row in df2.itertuples():\n",
    "    prompt = build_sqlquerygen_prompt(row.Question, row.Context)\n",
    "    prompts_list.append(prompt)\n",
    "results = llm.generate_threaded(prompts_list, max_workers=5)\n",
    "\n",
    "# Create a list to store the generated SQL queries\n",
    "generated_sql_queries = []\n",
    "for result in results:\n",
    "    generated_sql_query = result[0]\n",
    "    # print(f'generated_sql_query: {generated_sql_query}')\n",
    "    generated_sql_queries.append(generated_sql_query)\n",
    "\n",
    "# Add the new column 'Generated_SQL_Query' to df_results\n",
    "df2['Generated_SQL_Query'] = generated_sql_queries\n",
    "\n",
    "# Test generated SQL queries and verify they work\n",
    "results = []\n",
    "\n",
    "for row in df2.itertuples():\n",
    "    statement = util.extract_with_regex(row.Generated_SQL_Query, util.SQL_PATTERN)\n",
    "    # print(f'SQL statement: {statement}')\n",
    "    error = None\n",
    "    try:     \n",
    "        result = databaseutil.run_sql(statement)\n",
    "\n",
    "    except Exception as e:\n",
    "        error = e\n",
    "\n",
    "    results.append({'Question': row.Question,'Query': statement, 'Result': result, 'Error': error, 'ReferenceQuery': row.Query, 'Context': row.Context})\n",
    "\n",
    "df2_results = pd.DataFrame(results)\n",
    "\n",
    "# inspect first 3 results\n",
    "print(df2_results.head(3))\n",
    "\n",
    "# review successful/unsucessful queries\n",
    "df2_good_results = df2_results[df2_results['Error'].isnull() | (df2_results['Error'] == None)]\n",
    "print(f\"Number of successful queries: {len(df2_good_results)}\")\n",
    "\n",
    "df2_bad_results = df2_results[df2_results['Error'].notnull() | (df2_results['Error'] == 'None')]\n",
    "print(f\"Number of unsuccessful queries: {len(df2_bad_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this lab, we took ~1k examples that resemble our evaluation dataset and used them as few shot examples. Using dynamic few shot examples is the easiest way to improve the system over time using in context learning. \n",
    "\n",
    "In the next labs, we will fine tune an LLM using ~2k examples of SQL queries & general instruction following to train a 7 billion parameter model. To train a model, we need a GPU. We will use a G5.2xlarge which has a single NVidia A10. Within AWS Workshops, only SageMaker notebooks have a quota for a G5.2xlarge so we recommend you run through 3(a) instead of 3(b). In a production use case, we recommend using SageMaker training jobs like depicted in 3(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
