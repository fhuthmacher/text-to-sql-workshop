{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Bedrock Text-to-SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro and Goal\n",
    "This Jupyter Notebook is designed to illustrate a zero-shot Text-to-SQL approach on the Northwind database.\n",
    "\n",
    "The goal is to take a user prompt along with a SQL database schema, and then generate a corresponding SQL query.\n",
    "\n",
    "### Steps\n",
    "1. Download SQL schema\n",
    "2. Download ground truth dataset comprised of questions and SQL queries for a our sample database\n",
    "3. Generate and run SQL queries with a smaller LLM\n",
    "4. Generate and run SQL queries with a larger LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Create a python environment\n",
    "\n",
    "# !conda create -y --name text-to-sql python=3.11.8\n",
    "# !conda init && activate text-to-sql\n",
    "# !conda install -n text-to-sql ipykernel --update-deps --force-reinstall -y\n",
    "# !conda install -c conda-forge ipython-sql\n",
    "\n",
    "## OR\n",
    "# !python3 -m venv venv\n",
    "# !source venv/bin/activate  # On Windows, use `venv\\Scripts\\activate`\n",
    "\n",
    "# install ipykernel, which consists of IPython as well\n",
    "# !pip install ipykernel\n",
    "# create a kernel that can be used to run notebook commands inside the virtual environment\n",
    "# !python3 -m ipykernel install --user --name=venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Install dependencies\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Set Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Import necessary libraries and load environment variables\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "# loading environment variables that are stored in local file\n",
    "local_env_filename = 'dev.env'\n",
    "load_dotenv(find_dotenv(local_env_filename),override=True)\n",
    "\n",
    "os.environ['REGION'] = os.getenv('REGION')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')\n",
    "os.environ['SQL_DATABASE'] = os.getenv('SQL_DATABASE') # LOCAL, SQLALCHEMY, REDSHIFT\n",
    "os.environ['SQL_DIALECT'] = os.getenv('SQL_DIALECT') # SQlite, PostgreSQL\n",
    "\n",
    "\n",
    "REGION = os.environ['REGION']\n",
    "HF_TOKEN = os.environ['HF_TOKEN']\n",
    "SQL_DATABASE = os.environ['SQL_DATABASE']\n",
    "SQL_DIALECT = os.environ['SQL_DIALECT']\n",
    "\n",
    "print(f\"Using database: {SQL_DATABASE} with sql dialect: {SQL_DIALECT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Initialize database wrapper to run sql queries, get database schema, and create tables in database\n",
    "from utils.database import DatabaseUtil\n",
    "\n",
    "if SQL_DATABASE == 'SQLALCHEMY':\n",
    "        # SQLALCHEMY\n",
    "        databaseutil = DatabaseUtil(\n",
    "                        datasource_url=[\"https://d3q8adh3y5sxpk.cloudfront.net/sql-workshop/data/redshift-sourcedb.sql\"],\n",
    "                        sql_database= 'SQLALCHEMY',\n",
    "                        region=REGION\n",
    "        )\n",
    "\n",
    "if SQL_DATABASE == 'LOCAL':\n",
    "        # LOCAL SqlLite\n",
    "        databaseutil = DatabaseUtil(\n",
    "                        datasource_url=[\"https://d3q8adh3y5sxpk.cloudfront.net/sql-workshop/data/redshift-sourcedb.sql\"],\n",
    "                        sql_database= 'LOCAL'\n",
    "        )\n",
    "\n",
    "result = databaseutil.create_database_tables()\n",
    "print(result)\n",
    "           \n",
    "schema = databaseutil.get_schema_as_string()\n",
    "print(schema)\n",
    "\n",
    "# result = databaseutil.run_sql(\"SELECT * from public.customers\")\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Download ground truth \n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# URL of the file to download\n",
    "url = \"https://d3q8adh3y5sxpk.cloudfront.net/sql-workshop/data/question_query_good_results.jsonl\"\n",
    "\n",
    "# Path to the local data folder\n",
    "data_folder = \"./data\"\n",
    "\n",
    "# Create the data folder if it doesn't exist\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# File name to save the downloaded file\n",
    "file_name = \"ground_truth.jsonl\"\n",
    "\n",
    "# Full path to save the file\n",
    "file_path = os.path.join(data_folder, file_name)\n",
    "\n",
    "# Send a GET request to download the file\n",
    "response = requests.get(url)\n",
    "\n",
    "# Save the file to the local data folder\n",
    "with open(file_path, \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "print(f\"File downloaded and saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Validate - ensure ground truth SQL queries run successfully\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "results = []\n",
    "\n",
    "# Check if df exists in the current namespace\n",
    "if 'df' not in globals():\n",
    "    # If it doesn't exist, try to load it from a JSONL file\n",
    "    if os.path.exists(file_path):\n",
    "        # Load the dataframe from the JSONL file\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        print(\"df loaded from JSONL file.\")\n",
    "    else:\n",
    "        print(f\"Error: JSONL file not found at {file_path}\")\n",
    "else:\n",
    "    print(f\"df with column names: {df.columns} already exists in memory.\")\n",
    "\n",
    "df.columns = df.columns.str.capitalize()\n",
    "\n",
    "\n",
    "for row in df.itertuples():\n",
    "    # print(row.query)\n",
    "    error = None\n",
    "    result = None\n",
    "    try:\n",
    "        \n",
    "        result = databaseutil.run_sql(row.Query)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error = e\n",
    "\n",
    "    results.append({'Question': row.Question,'Query': row.Query, 'Result': result, 'Error': error, 'Context': schema})\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "df_good_results = df_results[df_results['Error'].isnull() | (df_results['Error'] == None)]\n",
    "print(f\"Number of successful queries: {len(df_good_results)}\")\n",
    "\n",
    "df_bad_results = df_results[df_results['Error'].notnull() | (df_results['Error'] == 'None')]\n",
    "print(f\"Number of unsuccessful queries: {len(df_bad_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Create Text-to-SQL zero-shot prompt\n",
    "# This function builds a text-to-SQL zero-shot prompt for a given user question and SQL database schema.\n",
    "# The prompt includes the original user question, the SQL database schema, and instructions for generating a SQL query.\n",
    "# The sql_dialect parameter specifies the SQL dialect to be used in the generated SQL query (e.g., MySQL, SQLite, etc.).\n",
    "\n",
    "def build_sqlquerygen_prompt(user_question: str, sql_database_schema: str):\n",
    "    prompt = \"\"\"You are a SQL expert. You will be provided with the original user question and a SQL database schema. \n",
    "                Only return the SQL query and nothing else.\n",
    "                Here is the original user question.\n",
    "                <user_question>\n",
    "                {user_question}\n",
    "                </user_question>\n",
    "\n",
    "                Here is the SQL database schema.\n",
    "                <sql_database_schema>\n",
    "                {sql_database_schema}\n",
    "                </sql_database_schema>\n",
    "                \n",
    "                Instructions:\n",
    "                Generate a SQL query that answers the original user question.\n",
    "                Use the schema, first create a syntactically correct {sql_dialect} query to answer the question. \n",
    "                Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
    "                Always prefix table names with the \"public.\" prefix.\n",
    "                Pay attention to use only the column names that you can see in the schema description. \n",
    "                Be careful to not query for columns that do not exist. \n",
    "                Pay attention to which column is in which table. \n",
    "                Also, qualify column names with the table name when needed.\n",
    "                If you cannot answer the user question with the help of the provided SQL database schema, \n",
    "                then output that this question question cannot be answered based of the information stored in the database.\n",
    "                You are required to use the following format, each taking one line.\n",
    "                Return the sql query inside the <SQL></SQL> tab.\n",
    "                \"\"\".format(\n",
    "                    user_question=user_question,\n",
    "                    sql_database_schema=sql_database_schema,\n",
    "                    sql_dialect=SQL_DIALECT\n",
    "                ) \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 8a. Use ground truth to run test with smaller LLM\n",
    "from utils.bedrock import BedrockLLMWrapper\n",
    "from utils.util import Util\n",
    "MODEL_ID = \"mistral.mistral-7b-instruct-v0:2\" # \"mistral.mixtral-8x7b-instruct-v0:1\" # \"anthropic.claude-3-haiku-20240307-v1:0\" # \"mistral.mixtral-8x7b-instruct-v0:1\" \"anthropic.claude-3-5-sonnet-20240620-v1:0\" \"meta.llama3-1-70b-instruct-v1:0\"\n",
    "\n",
    "# use helper class for threaded API calls\n",
    "llm = BedrockLLMWrapper(model_id=MODEL_ID, max_token_count=500, region=REGION)\n",
    "util = Util()\n",
    "df1 = df_good_results\n",
    "prompts_list = []\n",
    "for row in df1.itertuples():\n",
    "    prompt = build_sqlquerygen_prompt(row.Question, row.Context)\n",
    "    prompts_list.append(prompt)\n",
    "results = llm.generate_threaded(prompts_list)\n",
    "\n",
    "# Create a list to store the generated SQL queries\n",
    "generated_sql_queries = []\n",
    "for result in results:\n",
    "    generated_sql_query = result[0].replace(\"\\\\\",\"\") # workaround, switching to ConverseAPI introduced \\ in Mistral response\n",
    "    generated_sql_queries.append(generated_sql_query)\n",
    "\n",
    "# Add the new column 'Generated_SQL_Query' to df_results\n",
    "df1['Generated_SQL_Query'] = generated_sql_queries\n",
    "\n",
    "# Test generated SQL queries and verify they work\n",
    "results = []\n",
    "\n",
    "for row in df1.itertuples():\n",
    "    statement = util.extract_with_regex(row.Generated_SQL_Query, util.SQL_PATTERN)\n",
    "    error = None\n",
    "    result = None\n",
    "    try:    \n",
    "        result = databaseutil.run_sql(statement)\n",
    "\n",
    "    except Exception as e:\n",
    "        error = e\n",
    "\n",
    "    results.append({'Question': row.Question,'Query': statement, 'Result': result, 'Error': error, 'ReferenceQuery': row.Query, 'Context': row.Context})\n",
    "\n",
    "# inspect first 3 results\n",
    "df1_results = pd.DataFrame(results)\n",
    "print(df1_results.head(3))\n",
    "\n",
    "# review successful/unsucessful queries\n",
    "df1_good_results = df1_results[df1_results['Error'].isnull() | (df1_results['Error'] == None)]\n",
    "print(f\"Number of successful queries: {len(df1_good_results)}\")\n",
    "\n",
    "df1_bad_results = df1_results[df1_results['Error'].notnull() | (df1_results['Error'] == 'None')]\n",
    "print(f\"Number of unsuccessful queries: {len(df1_bad_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8b. Use ground truth to run test with larger LLM\n",
    "\n",
    "MODEL_ID = \"anthropic.claude-3-haiku-20240307-v1:0\" #\"anthropic.claude-3-sonnet-20240229-v1:0\"  \"mistral.mixtral-8x7b-instruct-v0:1\" \"anthropic.claude-3-5-sonnet-20240620-v1:0\" \"meta.llama3-1-70b-instruct-v1:0\"\n",
    "\n",
    "# use helper class for threaded API calls\n",
    "llm = BedrockLLMWrapper(model_id=MODEL_ID, max_token_count=500, region=REGION)\n",
    "util = Util()\n",
    "df2 = df_good_results\n",
    "prompts_list = []\n",
    "for row in df1.itertuples():\n",
    "    prompt = build_sqlquerygen_prompt(row.Question, row.Context)\n",
    "    prompts_list.append(prompt)\n",
    "results = llm.generate_threaded(prompts_list, max_workers=8)\n",
    "\n",
    "# Create a list to store the generated SQL queries\n",
    "generated_sql_queries = []\n",
    "for result in results:\n",
    "    generated_sql_query = result[0]\n",
    "    # print(f'generated_sql_query: {generated_sql_query}')\n",
    "    generated_sql_queries.append(generated_sql_query)\n",
    "\n",
    "# Add the new column 'Generated_SQL_Query' to df_results\n",
    "df2['Generated_SQL_Query'] = generated_sql_queries\n",
    "\n",
    "# Test generated SQL queries and verify they work\n",
    "results = []\n",
    "\n",
    "for row in df2.itertuples():\n",
    "    statement = util.extract_with_regex(row.Generated_SQL_Query, util.SQL_PATTERN)\n",
    "    # print(f'SQL statement: {statement}')\n",
    "    error = None\n",
    "    try:     \n",
    "        result = databaseutil.run_sql(statement)\n",
    "\n",
    "    except Exception as e:\n",
    "        error = e\n",
    "\n",
    "    results.append({'Question': row.Question,'Query': statement, 'Result': result, 'Error': error, 'ReferenceQuery': row.Query, 'Context': row.Context})\n",
    "\n",
    "df2_results = pd.DataFrame(results)\n",
    "\n",
    "# inspect first 3 results\n",
    "print(df2_results.head(3))\n",
    "\n",
    "# review successful/unsucessful queries\n",
    "df2_good_results = df2_results[df2_results['Error'].isnull() | (df2_results['Error'] == None)]\n",
    "print(f\"Number of successful queries: {len(df2_good_results)}\")\n",
    "\n",
    "df2_bad_results = df2_results[df2_results['Error'].notnull() | (df2_results['Error'] == 'None')]\n",
    "print(f\"Number of unsuccessful queries: {len(df2_bad_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "As expected, we can observe that a larger LLM (e.g. Haiku) is able to produce valid SQL queries more successfully with zero-shot prompting compared to a smaller LLM (e.g. Mistral 7b)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
